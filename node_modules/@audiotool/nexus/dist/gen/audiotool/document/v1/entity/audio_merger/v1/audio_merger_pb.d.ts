import { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage, Message, proto3 } from '@bufbuild/protobuf';
import { Empty } from '../../../empty_pb.js';

/**
 * Represents an audio merger device.
 *
 * The merger device takes audio from three inputs, A, B, C,
 * and mixes them according to coordinates on a triangle
 * spanned by points A, B, C.
 *
 * @generated from message audiotool.document.v1.entity.audio_merger.v1.AudioMerger
 */
export declare class AudioMerger extends Message<AudioMerger> {
    /**
     * Uniquely identifies the merger device.
     *
     * @generated from field: string id = 1;
     */
    id: string;
    /**
     * The user-assigned name of this device.
     *
     * @generated from field: string display_name = 2;
     */
    displayName: string;
    /**
     * X position on the desktop in the DAW.
     *
     * @generated from field: int32 position_x = 3;
     */
    positionX: number;
    /**
     * Y position on the desktop in the DAW.
     *
     * @generated from field: int32 position_y = 4;
     */
    positionY: number;
    /**
     * Selects the blending algorithm used to calculate the gains
     * of the input signals based on the distance to the points
     * A, B and C in the AudioMergerCoordinates below.
     *
     * - 0: invalid
     * - 1: full-power
     * - 2: equal-power
     *
     * The difference between algorithms is best understood when considering
     * the situation where all 3 input signals receive an identical sine wave
     * peak value 1.
     *
     * - full-power:
     *    Means the output will become louder when the knob is in the
     *    center - you will basically add all 3 signals, resulting in a sine wave
     *    with peak 3. If the knob is at e.g. point A, the signal will get gain 1.
     *
     * - equal-power:
     *    The output gain of the signal will be near-constant when moving the knob.
     *
     * @generated from field: uint32 blend_mode_index = 5;
     */
    blendModeIndex: number;
    /**
     * Location for the audio input A.
     *
     * @generated from field: audiotool.document.v1.Empty audio_input_a = 6;
     */
    audioInputA?: Empty;
    /**
     * Location for the audio input B.
     *
     * @generated from field: audiotool.document.v1.Empty audio_input_b = 7;
     */
    audioInputB?: Empty;
    /**
     * Location for the audio input C.
     *
     * @generated from field: audiotool.document.v1.Empty audio_input_c = 8;
     */
    audioInputC?: Empty;
    /**
     * Location for the audio input, contains a mix of A, B and C according to the
     * merge coords.
     *
     * @generated from field: audiotool.document.v1.Empty audio_output = 9;
     */
    audioOutput?: Empty;
    /**
     * Contains the coordinates determining the mix between A, B and C.
     *
     * @generated from field: audiotool.document.v1.entity.audio_merger.v1.AudioMergerCoordinates merge_coords = 10;
     */
    mergeCoords?: AudioMergerCoordinates;
    constructor(data?: PartialMessage<AudioMerger>);
    static readonly runtime: typeof proto3;
    static readonly typeName = "audiotool.document.v1.entity.audio_merger.v1.AudioMerger";
    static readonly fields: FieldList;
    static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AudioMerger;
    static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AudioMerger;
    static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AudioMerger;
    static equals(a: AudioMerger | PlainMessage<AudioMerger> | undefined, b: AudioMerger | PlainMessage<AudioMerger> | undefined): boolean;
}
/**
 * The coordinates by which signals A, B and C in the audio merger are mixed.
 *
 * The coordinates are on the cartesian plane bounded by [0, 1]
 * in both dimensions. On this plane, a triangle is formed between
 * points:
 * - A: (0, 0.5)
 * - B: (1, 0)
 * - C: (0, -0.5)
 *
 * For a given coordinate (x, y), the point is first clamped vertically
 * to be within the y-range of the triangle (for the given x value). Then,
 * the distance to points A, B, C is calculated.
 *
 * How these distances are used to mix the signals together depends
 * on the blend_algorithm fields of the merger.
 *
 * @generated from message audiotool.document.v1.entity.audio_merger.v1.AudioMergerCoordinates
 */
export declare class AudioMergerCoordinates extends Message<AudioMergerCoordinates> {
    /**
     * The x-coordinates. See the message documentation for what this means.
     *
     * @generated from field: float x = 1;
     */
    x: number;
    /**
     * The y-coordinates. See the message documentation for what this means.
     *
     * @generated from field: float y = 2;
     */
    y: number;
    constructor(data?: PartialMessage<AudioMergerCoordinates>);
    static readonly runtime: typeof proto3;
    static readonly typeName = "audiotool.document.v1.entity.audio_merger.v1.AudioMergerCoordinates";
    static readonly fields: FieldList;
    static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AudioMergerCoordinates;
    static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AudioMergerCoordinates;
    static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AudioMergerCoordinates;
    static equals(a: AudioMergerCoordinates | PlainMessage<AudioMergerCoordinates> | undefined, b: AudioMergerCoordinates | PlainMessage<AudioMergerCoordinates> | undefined): boolean;
}
